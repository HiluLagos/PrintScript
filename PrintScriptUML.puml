@startuml

interface Lexer {
+ setFile(input: File): void
+ getTokens(): List<Token>
}

interface Token {
+ getType(): TokenType
+ getString(): String
+ getLine(): Int
}

class TokenImpl {
- type: TokenType
- representation: String
- line: Int
+ toString(): String
}

enum TokenType {
+ KEYWORD
+ OPERAND
+ IDENTIFIER_TYPE
+ ASSIGNATION
+ ENDING
+ STRING_LITERAL
+ NUMBER_LITERAL
+ UNKNOWN
+ NATIVE_METHOD
+ PARENTHESIS
+ USER_METHOD
+ IDENTIFIER_VAR
}

class TypeProvider {
+ getTokenType(value: String): TokenType
}

class LexerImplementation {
- file: File
- readText(file: File): List<Token>
- splitText(splitter: ElementSplitter, text: String): List<Token>
}

class ElementSplitter {
- input: String
+ split(text: String): List<String>
- isQuote(c: Char): Boolean
- handleQuote(c: Char): void
- handleWhitespace(): void
- isSeparator(c: Char): Boolean
- handleSeparator(c: Char): void
- handleOpeningParenthesis(c: Char): void
- handleClosingParenthesis(c: Char): void
- handleDefault(c: char): void
- isDoubleCharOperator(): Boolean
- addTokenIfNotEmpty(): void
- addRemainingToken(): void
}

interface Parser {
+getAst(tkList: List<Token>): List<Node>
}

class ParserImpl {

}

interface Interpreter {
+interpret(astList: List<Node>): void
}

class InterpreterImpl {
}

interface Linter {
}

interface Formatter {
}

interface Node {
+analyze(): Result
}

class Result {
-valid: Boolean
-typeList: List<ResultType>
}

class Operand {
-left: Node
-right: Node
}

class Add {
-left: Node
-right: Node
}

class FunctionDeclaration {
-left: Node
-right: Node
}

class Function {
}

class NumberLiteral {
}
class StringLiteral {
}

LexerImplementation ..> Lexer
LexerImplementation --> ElementSplitter
LexerImplementation --> TypeProvider
Lexer --> Token
TokenImpl ..> Token
Token --> TokenType
Node --> Result
Operand ..> Node
Add ..> Node
FunctionDeclaration ..> Node
Function ..> Node
NumberLiteral ..> Node
StringLiteral ..> Node
ParserImpl ..> Parser
ParserImpl --> Node
InterpreterImpl ..> Interpreter
InterpreterImpl --> Node

@enduml